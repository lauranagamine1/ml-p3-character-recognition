# Proyecto 3: Reconocimiento de Caracteres EMNIST

## DescripciÃ³n

Este proyecto implementa un sistema completo de reconocimiento de caracteres manuscritos utilizando el dataset EMNIST (Extended MNIST). El sistema incluye preprocesamiento de datos, entrenamiento de un clasificador de **RegresiÃ³n LogÃ­stica Multinomial**, y una interfaz grÃ¡fica interactiva para clasificar caracteres dibujados a mano.

### CaracterÃ­sticas Principales

- **62 clases**: DÃ­gitos (0-9), letras mayÃºsculas (A-Z) y letras minÃºsculas (a-z)
- **697,932 imÃ¡genes de entrenamiento** y **116,323 imÃ¡genes de test**
- **RegresiÃ³n LogÃ­stica Multinomial** como clasificador
- **ReducciÃ³n de dimensionalidad con PCA** (784 â†’ 61 caracterÃ­sticas)
- **Interfaz grÃ¡fica interactiva** para dibujar y clasificar caracteres en tiempo real

---

## Estructura del Proyecto

```
ml-p3-character-recognition/
â”‚
â”œâ”€â”€ data/                                  # Datos EMNIST originales (CSV)
â”‚   â”œâ”€â”€ emnist-byclass-train.csv
â”‚   â”œâ”€â”€ emnist-byclass-test.csv
â”‚   â””â”€â”€ emnist-byclass-mapping.txt
â”‚
â”œâ”€â”€ preprocesamiento/                      # Preprocesamiento de datos
â”‚   â”œâ”€â”€ preprocesamiento.ipynb            # Notebook de preprocesamiento + EDA
â”‚   â”œâ”€â”€ class_mapping.pkl                 # Mapeo de clases (label â†’ carÃ¡cter)
â”‚   â””â”€â”€ output/
â”‚       â”œâ”€â”€ emnist_train_processed.npz    # Train sin PCA (697,932 Ã— 28 Ã— 28)
â”‚       â”œâ”€â”€ emnist_train_reduced.npz      # Train con PCA (697,932 Ã— 61)
â”‚       â”œâ”€â”€ emnist_test_processed.npz     # Test sin PCA (116,323 Ã— 28 Ã— 28)
â”‚       â””â”€â”€ emnist_test_reduced.npz       # Test con PCA (116,323 Ã— 61)
â”‚
â”œâ”€â”€ classification/                        # Modelos de clasificaciÃ³n
â”‚   â””â”€â”€ logistic-regression/
â”‚       â”œâ”€â”€ logistic_regression.ipynb     # Notebook de entrenamiento y evaluaciÃ³n
â”‚       â””â”€â”€ output/
â”‚           â”œâ”€â”€ logistic_regression_model.pkl  # Modelo entrenado
â”‚           â”œâ”€â”€ class_mapping.pkl              # Mapeo de clases
â”‚           â””â”€â”€ metrics.pkl                    # MÃ©tricas del modelo
â”‚
â”œâ”€â”€ graphic-interface/                     # Interfaz grÃ¡fica
â”‚   â”œâ”€â”€ character_recognizer_gui.py       # AplicaciÃ³n principal
â”‚   â””â”€â”€ requirements.txt                  # Dependencias
â”‚
â”œâ”€â”€ README.md                              # Este archivo
â”œâ”€â”€ QUICKSTART.md                          # GuÃ­a rÃ¡pida de inicio
â””â”€â”€ check_installation.py                 # Script de verificaciÃ³n
```

---

## InstalaciÃ³n

### Requisitos Previos

- Python 3.8 o superior
- pip (gestor de paquetes de Python)

### Instalar Dependencias

```bash
pip install numpy pandas matplotlib seaborn scikit-learn jupyter pillow opencv-python
```

O por separado:

**Para entrenamiento:**
```bash
pip install numpy pandas matplotlib seaborn scikit-learn jupyter
```

**Para interfaz grÃ¡fica:**
```bash
pip install numpy pillow opencv-python scikit-learn
```

---

## Uso del Sistema

### 1. Preprocesamiento de Datos (Ya completado)

Los datos ya estÃ¡n preprocesados y disponibles en `preprocesamiento/output/`:
- **Train con PCA**: `emnist_train_reduced.npz` (697,932 Ã— 61)
- **Test con PCA**: `emnist_test_reduced.npz` (116,323 Ã— 61)

El preprocesamiento incluye:
- BinarizaciÃ³n con umbral de Otsu
- NormalizaciÃ³n
- PCA (784 dimensiones â†’ 61 componentes)

Si deseas revisar el proceso:
```bash
cd preprocesamiento
jupyter notebook preprocesamiento.ipynb
```

### 2. Entrenamiento del Modelo de RegresiÃ³n LogÃ­stica

Para entrenar el modelo:

```bash
cd classification/logistic-regression
jupyter notebook logistic_regression.ipynb
```

**El notebook incluye:**

1. **Carga de Datos**
   - Datos con PCA ya aplicado (61 features)
   - 697,932 muestras de entrenamiento
   - 116,323 muestras de test

2. **Entrenamiento**
   - RegresiÃ³n LogÃ­stica Multinomial
   - Solver: `lbfgs` (optimizado para multiclase)
   - RegularizaciÃ³n L2 (C=1.0)
   - Entrenamiento con paralelizaciÃ³n

3. **EvaluaciÃ³n Completa**
   - MÃ©tricas globales: Accuracy, Precision, Recall, F1-Score
   - Reporte de clasificaciÃ³n por clase
   - Matriz de confusiÃ³n y versiÃ³n normalizada
   - AnÃ¡lisis de errores mÃ¡s frecuentes
   - DistribuciÃ³n de confianza en predicciones

4. **Guardado del Modelo**
   - Modelo entrenado
   - Mapeo de clases
   - MÃ©tricas de rendimiento

**Ejecuta todas las celdas** (Cell â†’ Run All) para entrenar y guardar el modelo.

### 3. Interfaz GrÃ¡fica

Para ejecutar la interfaz grÃ¡fica interactiva:

```bash
cd graphic-interface
python character_recognizer_gui.py
```

**Funcionalidades:**

- **Canvas de Dibujo**: Dibuja caracteres con el mouse
- **Control de Grosor**: Ajusta el tamaÃ±o del pincel (5-40 px)
- **BotÃ³n Limpiar**: Reinicia el canvas
- **BotÃ³n Clasificar**: Procesa y clasifica el carÃ¡cter dibujado
- **PredicciÃ³n Principal**: Muestra el carÃ¡cter con mayor confianza
- **Top 5 Predicciones**: Lista las 5 predicciones mÃ¡s probables
- **Imagen Procesada**: Visualiza la imagen despuÃ©s del preprocesamiento (28Ã—28)
- **InformaciÃ³n del Modelo**: Muestra mÃ©tricas de rendimiento

**CÃ³mo usar:**

1. Dibuja un dÃ­gito (0-9) o letra (A-Z, a-z) en el Ã¡rea blanca
2. Ajusta el grosor del pincel si es necesario
3. Haz clic en "ğŸ” Clasificar"
4. Observa el resultado, confianza y top 5 predicciones
5. Usa "ğŸ—‘ Limpiar" para dibujar otro carÃ¡cter

---

## Rendimiento del Modelo

### MÃ©tricas de EvaluaciÃ³n

El modelo se evalÃºa con mÃºltiples mÃ©tricas:
- **Accuracy**: ProporciÃ³n de predicciones correctas
- **Precision**: Exactitud de las predicciones positivas
- **Recall**: Cobertura de las clases verdaderas
- **F1-Score**: Media armÃ³nica de Precision y Recall

*(Los valores exactos se generan al ejecutar el notebook y se muestran en la interfaz)*

### CaracterÃ­sticas del Modelo

- **Algoritmo**: RegresiÃ³n LogÃ­stica Multinomial
- **Solver**: lbfgs (optimizado para multiclase)
- **RegularizaciÃ³n**: L2 (C=1.0)
- **Clases**: 62 (0-9, A-Z, a-z)
- **Features**: 61 (reducidas con PCA)
- **Varianza explicada por PCA**: ~95%

### AnÃ¡lisis de Resultados

**Fortalezas:**
- âœ… Entrenamiento rÃ¡pido (~5-15 minutos)
- âœ… PredicciÃ³n en tiempo real
- âœ… Buen rendimiento general en dÃ­gitos
- âœ… Modelo interpretable (coeficientes lineales)
- âœ… Bajo costo computacional

**DesafÃ­os comunes:**
- ConfusiÃ³n entre caracteres visualmente similares:
  - O (letra) vs 0 (cero)
  - I (mayÃºscula) vs l (L minÃºscula) vs 1 (uno)
  - S vs 5
  - Z vs 2
  - MayÃºsculas vs minÃºsculas similares (C/c, O/o, S/s)

---

## JustificaciÃ³n de Decisiones de DiseÃ±o

### 1. Preprocesamiento

**BinarizaciÃ³n con Umbral de Otsu:**
- Reduce ruido y variabilidad en las imÃ¡genes
- Mejora la robustez del modelo
- Estandariza las imÃ¡genes a valores binarios (0 o 1)

**PCA (784 â†’ 61 dimensiones):**
- **Eficiencia**: Reduce tiempo de entrenamiento ~92%
- **Previene overfitting**: Menos parÃ¡metros a aprender
- **Elimina ruido**: Mantiene solo componentes con mayor varianza
- **Preserva informaciÃ³n**: ~95% de varianza explicada
- **Compatibilidad**: Mejora convergencia de algoritmos lineales

### 2. RegresiÃ³n LogÃ­stica Multinomial

**Â¿Por quÃ© RegresiÃ³n LogÃ­stica?**

âœ… **Ventajas:**
- **Eficiente**: RÃ¡pido para datasets grandes (697K muestras)
- **Multiclase nativo**: Maneja 62 clases con `multi_class='multinomial'`
- **PredicciÃ³n en tiempo real**: Ideal para interfaz interactiva
- **Interpretable**: Coeficientes lineales por clase
- **RegularizaciÃ³n L2**: Previene overfitting automÃ¡ticamente
- **Funciona bien con PCA**: Asume linealidad en espacio transformado
- **Convergencia estable**: Solver lbfgs es robusto

âŒ **Limitaciones:**
- Asume relaciones lineales (fronteras de decisiÃ³n lineales)
- Rendimiento inferior a modelos mÃ¡s complejos (CNNs, XGBoost)
- Dificultad con caracteres muy similares

**ParÃ¡metros seleccionados:**
- `solver='lbfgs'`: Optimizado para problemas multiclase grandes
- `multi_class='multinomial'`: Modelo multinomial (softmax)
- `C=1.0`: RegularizaciÃ³n L2 estÃ¡ndar
- `max_iter=1000`: Suficientes iteraciones para convergencia
- `n_jobs=-1`: ParalelizaciÃ³n usando todos los cores

### 3. Interfaz GrÃ¡fica

**TecnologÃ­a: Tkinter**
- Biblioteca estÃ¡ndar de Python (sin instalaciÃ³n adicional)
- Multiplataforma (Windows, Mac, Linux)
- Suficiente para aplicaciÃ³n interactiva

**Preprocesamiento en tiempo real:**
- DetecciÃ³n automÃ¡tica de regiÃ³n de interÃ©s (OpenCV)
- Centrado del carÃ¡cter
- Redimensionamiento a 28Ã—28
- BinarizaciÃ³n con umbral

**CaracterÃ­sticas de usabilidad:**
- Control de grosor: Adaptabilidad a estilos de dibujo
- VisualizaciÃ³n procesada: Transparencia del preprocesamiento
- Top 5 predicciones: Contexto sobre alternativas