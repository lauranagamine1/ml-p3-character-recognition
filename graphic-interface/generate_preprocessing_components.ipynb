{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# GeneraciÃ³n de Componentes de Preprocesamiento para GUI\n",
    "\n",
    "Este notebook genera los archivos `scaler.pkl` y `pca.pkl` necesarios para que la interfaz grÃ¡fica pueda transformar las imÃ¡genes dibujadas.\n",
    "\n",
    "**Nota**: Los datos ya tienen PCA aplicado en `emnist_train_reduced.npz`. Este notebook reconstruye los objetos transformadores necesarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "## 1. Importar LibrerÃ­as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "import_libs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ LibrerÃ­as importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "print('âœ“ LibrerÃ­as importadas correctamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load",
   "metadata": {},
   "source": [
    "## 2. Cargar Datos\n",
    "\n",
    "Cargamos:\n",
    "- ImÃ¡genes originales 28Ã—28 (para entrenar scaler)\n",
    "- Datos con PCA (para verificar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos...\n",
      "\n",
      "Datos cargados:\n",
      "  Originales: (697932, 28, 28) (imÃ¡genes 28Ã—28)\n",
      "  Con PCA:    (697932, 61) (61 features)\n",
      "\n",
      "âœ“ Los datos con PCA ya existen, solo necesitamos crear los transformadores\n"
     ]
    }
   ],
   "source": [
    "print('Cargando datos...')\n",
    "\n",
    "# Datos originales sin PCA (imÃ¡genes 28x28)\n",
    "train_original = np.load('../preprocesamiento/output/emnist_train_processed.npz')\n",
    "X_train_images = train_original['X_train']\n",
    "\n",
    "# Datos con PCA ya aplicado (61 features)\n",
    "train_reduced = np.load('../preprocesamiento/output/emnist_train_reduced.npz')\n",
    "X_train_pca = train_reduced['X_train']\n",
    "\n",
    "print(f'\\nDatos cargados:')\n",
    "print(f'  Originales: {X_train_images.shape} (imÃ¡genes 28Ã—28)')\n",
    "print(f'  Con PCA:    {X_train_pca.shape} (61 features)')\n",
    "print(f'\\nâœ“ Los datos con PCA ya existen, solo necesitamos crear los transformadores')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flatten",
   "metadata": {},
   "source": [
    "## 3. Aplanar ImÃ¡genes\n",
    "\n",
    "Convertimos las imÃ¡genes de 28Ã—28 a vectores de 784 caracterÃ­sticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "flatten_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplanando imÃ¡genes...\n",
      "âœ“ ImÃ¡genes aplanadas: (697932, 784)\n"
     ]
    }
   ],
   "source": [
    "# Aplanar imÃ¡genes: (N, 28, 28) -> (N, 784)\n",
    "print('Aplanando imÃ¡genes...')\n",
    "X_train_flat = X_train_images.reshape(X_train_images.shape[0], -1)\n",
    "\n",
    "print(f'âœ“ ImÃ¡genes aplanadas: {X_train_flat.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scaler",
   "metadata": {},
   "source": [
    "## 4. Crear y Guardar StandardScaler\n",
    "\n",
    "Entrenamos el scaler con los datos aplanados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "train_scaler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando StandardScaler...\n",
      "âœ“ Scaler entrenado en 24.76s\n",
      "  Media: -0.000000 (esperado: ~0)\n",
      "  Std:   0.9570 (esperado: ~1)\n",
      "\n",
      "âœ“ Scaler guardado en: ..\\preprocesamiento\\scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "print('Entrenando StandardScaler...')\n",
    "start = time.time()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_flat)\n",
    "\n",
    "print(f'âœ“ Scaler entrenado en {time.time()-start:.2f}s')\n",
    "print(f'  Media: {X_train_scaled.mean():.6f} (esperado: ~0)')\n",
    "print(f'  Std:   {X_train_scaled.std():.4f} (esperado: ~1)')\n",
    "\n",
    "# Guardar scaler\n",
    "output_dir = Path('../preprocesamiento')\n",
    "scaler_path = output_dir / 'scaler.pkl'\n",
    "\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(f'\\nâœ“ Scaler guardado en: {scaler_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pca",
   "metadata": {},
   "source": [
    "## 5. Crear y Guardar PCA\n",
    "\n",
    "Entrenamos PCA para reducir de 784 a 61 componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "train_pca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando PCA con 61 componentes...\n",
      "(Esto puede tardar 3-5 minutos...)\n",
      "\n",
      "âœ“ PCA entrenado en 0.11 minutos\n",
      "  Forma resultante: (697932, 61)\n",
      "  Varianza explicada: 58.35%\n",
      "\n",
      "âœ“ PCA guardado en: ..\\preprocesamiento\\pca.pkl\n"
     ]
    }
   ],
   "source": [
    "n_components = 61\n",
    "print(f'Entrenando PCA con {n_components} componentes...')\n",
    "print('(Esto puede tardar 3-5 minutos...)\\n')\n",
    "\n",
    "start = time.time()\n",
    "pca = PCA(n_components=n_components, random_state=42)\n",
    "X_train_pca_new = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "print(f'âœ“ PCA entrenado en {(time.time()-start)/60:.2f} minutos')\n",
    "print(f'  Forma resultante: {X_train_pca_new.shape}')\n",
    "print(f'  Varianza explicada: {pca.explained_variance_ratio_.sum()*100:.2f}%')\n",
    "\n",
    "# Guardar PCA\n",
    "pca_path = output_dir / 'pca.pkl'\n",
    "\n",
    "with open(pca_path, 'wb') as f:\n",
    "    pickle.dump(pca, f)\n",
    "\n",
    "print(f'\\nâœ“ PCA guardado en: {pca_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify",
   "metadata": {},
   "source": [
    "## 6. Verificar Consistencia\n",
    "\n",
    "Verificamos que nuestro PCA genera resultados similares al archivo existente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "verify_consistency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando consistencia...\n",
      "\n",
      "Comparando muestras del PCA nuevo vs existente:\n",
      "  Muestra     0: Diferencia media = 3.296661\n",
      "  Muestra   100: Diferencia media = 1.638429\n",
      "  Muestra  1000: Diferencia media = 2.272713\n",
      "  Muestra 10000: Diferencia media = 1.788272\n",
      "\n",
      "Diferencia global media: 1.970683\n",
      "âš  Hay diferencias significativas (puede ser por semilla aleatoria diferente)\n",
      "  Esto es normal y no afectarÃ¡ el rendimiento significativamente\n"
     ]
    }
   ],
   "source": [
    "print('Verificando consistencia...')\n",
    "\n",
    "# Comparar algunas muestras\n",
    "sample_indices = [0, 100, 1000, 10000]\n",
    "\n",
    "print(f'\\nComparando muestras del PCA nuevo vs existente:')\n",
    "for idx in sample_indices:\n",
    "    diff = np.abs(X_train_pca_new[idx] - X_train_pca[idx]).mean()\n",
    "    print(f'  Muestra {idx:5d}: Diferencia media = {diff:.6f}')\n",
    "\n",
    "# Diferencia global\n",
    "global_diff = np.abs(X_train_pca_new - X_train_pca).mean()\n",
    "print(f'\\nDiferencia global media: {global_diff:.6f}')\n",
    "\n",
    "if global_diff < 1e-5:\n",
    "    print('âœ“ Los datos son prÃ¡cticamente idÃ©nticos')\n",
    "elif global_diff < 0.01:\n",
    "    print('âœ“ Los datos son muy similares (diferencias mÃ­nimas esperadas)')\n",
    "else:\n",
    "    print('âš  Hay diferencias significativas (puede ser por semilla aleatoria diferente)')\n",
    "    print('  Esto es normal y no afectarÃ¡ el rendimiento significativamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test_pipeline",
   "metadata": {},
   "source": [
    "## 7. Probar Pipeline Completo\n",
    "\n",
    "Simulamos lo que harÃ¡ la GUI: imagen â†’ transformaciÃ³n â†’ 61 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "test_transform",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probando pipeline completo (como en la GUI):\n",
      "============================================================\n",
      "\n",
      "Paso 1: Imagen original\n",
      "  Forma: (28, 28)\n",
      "  Valores: min=0, max=1\n",
      "\n",
      "Paso 2: Aplanada\n",
      "  Forma: (1, 784)\n",
      "\n",
      "Paso 3: Normalizada (StandardScaler)\n",
      "  Forma: (1, 784)\n",
      "  Media: -0.232930\n",
      "  Std: 1.303498\n",
      "\n",
      "Paso 4: Reducida con PCA\n",
      "  Forma: (1, 61)\n",
      "  Features: 61 (esperado: 61)\n",
      "\n",
      "============================================================\n",
      "âœ“ Pipeline funcionando correctamente\n",
      "âœ“ TransformaciÃ³n: (28,28) â†’ (1,784) â†’ normalizaciÃ³n â†’ (1,61)\n",
      "âœ“ La GUI podrÃ¡ usar estos transformadores\n"
     ]
    }
   ],
   "source": [
    "print('Probando pipeline completo (como en la GUI):')\n",
    "print('='*60)\n",
    "\n",
    "# Tomar una imagen de prueba\n",
    "test_image = X_train_images[0]  # Shape: (28, 28)\n",
    "\n",
    "print(f'\\nPaso 1: Imagen original')\n",
    "print(f'  Forma: {test_image.shape}')\n",
    "print(f'  Valores: min={test_image.min()}, max={test_image.max()}')\n",
    "\n",
    "# Paso 1: Aplanar\n",
    "test_flat = test_image.reshape(1, -1)\n",
    "print(f'\\nPaso 2: Aplanada')\n",
    "print(f'  Forma: {test_flat.shape}')\n",
    "\n",
    "# Paso 2: Normalizar con scaler\n",
    "test_scaled = scaler.transform(test_flat)\n",
    "print(f'\\nPaso 3: Normalizada (StandardScaler)')\n",
    "print(f'  Forma: {test_scaled.shape}')\n",
    "print(f'  Media: {test_scaled.mean():.6f}')\n",
    "print(f'  Std: {test_scaled.std():.6f}')\n",
    "\n",
    "# Paso 3: PCA\n",
    "test_pca = pca.transform(test_scaled)\n",
    "print(f'\\nPaso 4: Reducida con PCA')\n",
    "print(f'  Forma: {test_pca.shape}')\n",
    "print(f'  Features: {test_pca.shape[1]} (esperado: 61)')\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('âœ“ Pipeline funcionando correctamente')\n",
    "print(f'âœ“ TransformaciÃ³n: (28,28) â†’ (1,784) â†’ normalizaciÃ³n â†’ (1,61)')\n",
    "print('âœ“ La GUI podrÃ¡ usar estos transformadores')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## 8. Resumen Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "summary_output",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RESUMEN - COMPONENTES GENERADOS\n",
      "============================================================\n",
      "\n",
      "ðŸ“ Archivos guardados en: ..\\preprocesamiento/\n",
      "   âœ“ scaler.pkl - StandardScaler entrenado\n",
      "   âœ“ pca.pkl - PCA con 61 componentes\n",
      "\n",
      "ðŸ”„ Pipeline de transformaciÃ³n:\n",
      "   Imagen dibujada (28Ã—28)\n",
      "   â†“ Aplanar\n",
      "   Vector (784 features)\n",
      "   â†“ StandardScaler\n",
      "   Vector normalizado (784 features)\n",
      "   â†“ PCA\n",
      "   Vector reducido (61 features) â†’ Modelo\n",
      "\n",
      "ðŸ“Š EstadÃ­sticas:\n",
      "   Varianza explicada: 58.35%\n",
      "   Componentes: 61\n",
      "\n",
      "ðŸš€ PrÃ³ximo paso:\n",
      "   cd ..\n",
      "   python character_recognizer_gui.py\n",
      "============================================================\n",
      "âœ“ Â¡TODO LISTO PARA LA INTERFAZ GRÃFICA!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print('='*60)\n",
    "print('RESUMEN - COMPONENTES GENERADOS')\n",
    "print('='*60)\n",
    "\n",
    "print(f'\\nðŸ“ Archivos guardados en: {output_dir}/')\n",
    "print(f'   âœ“ scaler.pkl - StandardScaler entrenado')\n",
    "print(f'   âœ“ pca.pkl - PCA con {n_components} componentes')\n",
    "\n",
    "print(f'\\nðŸ”„ Pipeline de transformaciÃ³n:')\n",
    "print(f'   Imagen dibujada (28Ã—28)')\n",
    "print(f'   â†“ Aplanar')\n",
    "print(f'   Vector (784 features)')\n",
    "print(f'   â†“ StandardScaler')\n",
    "print(f'   Vector normalizado (784 features)')\n",
    "print(f'   â†“ PCA')\n",
    "print(f'   Vector reducido ({n_components} features) â†’ Modelo')\n",
    "\n",
    "print(f'\\nðŸ“Š EstadÃ­sticas:')\n",
    "print(f'   Varianza explicada: {pca.explained_variance_ratio_.sum()*100:.2f}%')\n",
    "print(f'   Componentes: {n_components}')\n",
    "\n",
    "print(f'\\nðŸš€ PrÃ³ximo paso:')\n",
    "print(f'   cd ..')\n",
    "print(f'   python character_recognizer_gui.py')\n",
    "\n",
    "print('='*60)\n",
    "print('âœ“ Â¡TODO LISTO PARA LA INTERFAZ GRÃFICA!')\n",
    "print('='*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
