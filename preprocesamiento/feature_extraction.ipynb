{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca3c89bd",
   "metadata": {},
   "source": [
    "# Image Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07632aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# skimage feature + morphology + measurement\n",
    "from skimage.feature import local_binary_pattern, hog as sk_hog\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.measure import label, regionprops, moments_hu, euler_number\n",
    "\n",
    "# numeric helpers\n",
    "from scipy.ndimage import convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca64192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"output/emnist_train_processed.npz\"\n",
    "test_path = \"output/emnist_test_processed.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef88cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (697932, 28, 28)\tTrain labels shape: (697932,)\n",
      "Test set shape: (116323, 28, 28)\tTest labels shape: (116323,)\n"
     ]
    }
   ],
   "source": [
    "with np.load(train_path) as data:\n",
    "    X_train = data['X_train']\n",
    "    y_train = data['y_train']\n",
    "\n",
    "with np.load(test_path) as data:\n",
    "    X_test = data['X_test']\n",
    "    y_test = data['y_test']\n",
    "\n",
    "print(f\"Train set shape: {X_train.shape}, Train labels shape: {y_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}, Test labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "65a5cba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoning(img):\n",
    "    if img is None:\n",
    "        return np.zeros(72, dtype=np.float32)\n",
    "    if img.ndim == 1:\n",
    "        side = int(np.sqrt(img.size))\n",
    "        img = img.reshape(side, side)\n",
    "    img = img.astype(np.float32, copy=False)\n",
    "    bin_img = (img > 0).astype(np.float32)\n",
    "    h, w = bin_img.shape\n",
    "    gh, gw = h // 4, w // 4\n",
    "    densities = []\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            patch = bin_img[i*gh:(i+1)*gh, j*gw:(j+1)*gw]\n",
    "            densities.append(patch.mean())\n",
    "    proj_h = bin_img.sum(axis=1)\n",
    "    proj_v = bin_img.sum(axis=0)\n",
    "    proj_h = proj_h / (proj_h.sum() + 1e-7)\n",
    "    proj_v = proj_v / (proj_v.sum() + 1e-7)\n",
    "    return np.concatenate([np.array(densities, dtype=np.float32),\n",
    "                           proj_h.astype(np.float32),\n",
    "                           proj_v.astype(np.float32)]).astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "def hog(img):\n",
    "    if img is None:\n",
    "        return np.zeros(1, dtype=np.float32)\n",
    "    if img.ndim == 1:\n",
    "        side = int(np.sqrt(img.size))\n",
    "        img = img.reshape(side, side)\n",
    "    img = img.astype(np.float32, copy=False)\n",
    "    if img.max() > 1.0:\n",
    "        img = img / 255.0\n",
    "    features = sk_hog(img,\n",
    "                      orientations=9,\n",
    "                      pixels_per_cell=(4, 4),\n",
    "                      cells_per_block=(2, 2),\n",
    "                      block_norm='L2-Hys',\n",
    "                      transform_sqrt=True,\n",
    "                      visualize=False,\n",
    "                      feature_vector=True)\n",
    "    return features.astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "def hu(img):\n",
    "    if img is None:\n",
    "        return np.zeros(7, dtype=np.float32)\n",
    "    if img.ndim == 1:\n",
    "        side = int(np.sqrt(img.size))\n",
    "        img = img.reshape(side, side)\n",
    "    bin_img = (img > 0).astype(np.float32)\n",
    "    vals = moments_hu(bin_img)\n",
    "    vals = -np.sign(vals) * np.log10(np.abs(vals) + 1e-10)\n",
    "    return vals.astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "def lbp(img):\n",
    "    if img is None:\n",
    "        return np.zeros(10, dtype=np.float32)\n",
    "    if img.ndim == 1:\n",
    "        side = int(np.sqrt(img.size))\n",
    "        img = img.reshape(side, side)\n",
    "    # prepare image for LBP: use integer dtype to avoid skimage warning\n",
    "    # convert floats to uint8 (scale if in 0..1), otherwise clip to 0..255 and cast\n",
    "    if img.dtype.kind == 'f':\n",
    "        if img.max() <= 1.0:\n",
    "            img_uint = (np.clip(img, 0.0, 1.0) * 255).astype(np.uint8)\n",
    "        else:\n",
    "            img_uint = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    else:\n",
    "        img_uint = img.astype(np.uint8, copy=False)\n",
    "    lbp_img = local_binary_pattern(img_uint, P=8, R=1, method='uniform')\n",
    "    hist, _ = np.histogram(lbp_img.ravel(), bins=10, range=(0, 10))\n",
    "    hist = hist.astype(np.float32)\n",
    "    hist /= (hist.sum() + 1e-7)\n",
    "    return hist.astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "def skeleton(img):\n",
    "    if img is None:\n",
    "        return np.zeros(4, dtype=np.float32)\n",
    "    if img.ndim == 1:\n",
    "        side = int(np.sqrt(img.size))\n",
    "        img = img.reshape(side, side)\n",
    "    bin_img = (img > 0).astype(np.uint8)\n",
    "    skel = skeletonize(bin_img > 0)\n",
    "    skel_uint = skel.astype(np.uint8)\n",
    "    kernel = np.array([[1,1,1],[1,0,1],[1,1,1]], dtype=np.uint8)\n",
    "    neighbor_count = convolve(skel_uint, kernel, mode='constant', cval=0)\n",
    "    endpoints = np.sum((skel_uint == 1) & (neighbor_count == 1))\n",
    "    branches = np.sum((skel_uint == 1) & (neighbor_count >= 3))\n",
    "    length = skel_uint.sum()\n",
    "    area = bin_img.sum()\n",
    "    ratio = length / (area + 1e-7)\n",
    "    return np.array([length, endpoints, branches, ratio], dtype=np.float32)\n",
    "\n",
    "\n",
    "def countours(img):\n",
    "    if img is None:\n",
    "        return np.zeros(6, dtype=np.float32)\n",
    "    if img.ndim == 1:\n",
    "        side = int(np.sqrt(img.size))\n",
    "        img = img.reshape(side, side)\n",
    "    bin_img = (img > 0).astype(np.uint8)\n",
    "    lbl = label(bin_img)\n",
    "    props = regionprops(lbl)\n",
    "    if not props:\n",
    "        return np.zeros(6, dtype=np.float32)\n",
    "    main = max(props, key=lambda r: r.area)\n",
    "    minr, minc, maxr, maxc = main.bbox\n",
    "    height = maxr - minr\n",
    "    width = maxc - minc\n",
    "    aspect = width / (height + 1e-7)\n",
    "    perimeter = main.perimeter if hasattr(main, 'perimeter') else 0.0\n",
    "    feats = [main.area, main.eccentricity, main.extent, main.solidity, aspect, perimeter]\n",
    "    return np.array(feats, dtype=np.float32)\n",
    "\n",
    "\n",
    "def pixel_run_length(img):\n",
    "    if img is None:\n",
    "        return np.zeros(6, dtype=np.float32)\n",
    "    if img.ndim == 1:\n",
    "        side = int(np.sqrt(img.size))\n",
    "        img = img.reshape(side, side)\n",
    "    bin_img = (img > 0).astype(np.uint8)\n",
    "\n",
    "    def runs_1d(arr):\n",
    "        runs = []\n",
    "        count = 0\n",
    "        for v in arr:\n",
    "            if v == 1:\n",
    "                count += 1\n",
    "            elif count > 0:\n",
    "                runs.append(count)\n",
    "                count = 0\n",
    "        if count > 0:\n",
    "            runs.append(count)\n",
    "        if not runs:\n",
    "            return [0]\n",
    "        return runs\n",
    "\n",
    "    horiz_runs = []\n",
    "    for row in bin_img:\n",
    "        horiz_runs.extend(runs_1d(row))\n",
    "    vert_runs = []\n",
    "    for col in bin_img.T:\n",
    "        vert_runs.extend(runs_1d(col))\n",
    "\n",
    "    horiz_runs = np.array(horiz_runs, dtype=np.float32)\n",
    "    vert_runs = np.array(vert_runs, dtype=np.float32)\n",
    "\n",
    "    def stats(vec):\n",
    "        return np.array([vec.mean(), vec.std(), vec.max()], dtype=np.float32) if vec.size else np.zeros(3, dtype=np.float32)\n",
    "\n",
    "    return np.concatenate([stats(horiz_runs), stats(vert_runs)]).astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "def connectivity(img):\n",
    "    \"\"\"Devuelve: [n_components, euler_number]\"\"\"\n",
    "    if img is None:\n",
    "        return np.zeros(2, dtype=np.float32)\n",
    "    if img.ndim == 1:\n",
    "        side = int(np.sqrt(img.size))\n",
    "        img = img.reshape(side, side)\n",
    "    bin_img = (img > 0).astype(np.uint8)\n",
    "    lbl = label(bin_img)\n",
    "    n_components = int(lbl.max())\n",
    "    try:\n",
    "        euler = float(euler_number(bin_img))\n",
    "    except Exception:\n",
    "        # fallback: sum of region euler numbers\n",
    "        props = regionprops(lbl)\n",
    "        euler = float(sum([p.euler_number for p in props])) if props else 0.0\n",
    "    return np.array([n_components, euler], dtype=np.float32)\n",
    "\n",
    "\n",
    "def geometry(img):\n",
    "    \"\"\"Devuelve 7 features: bbox(4), centroid(2), moment_of_inertia(1)\"\"\"\n",
    "    if img is None:\n",
    "        return np.zeros(7, dtype=np.float32)\n",
    "    if img.ndim == 1:\n",
    "        side = int(np.sqrt(img.size))\n",
    "        img = img.reshape(side, side)\n",
    "    bin_img = (img > 0).astype(np.uint8)\n",
    "    lbl = label(bin_img)\n",
    "    props = regionprops(lbl)\n",
    "    if not props:\n",
    "        return np.zeros(7, dtype=np.float32)\n",
    "    main = max(props, key=lambda r: r.area)\n",
    "    minr, minc, maxr, maxc = main.bbox\n",
    "    cy, cx = main.centroid\n",
    "    # momento de inercia: sum((x-cx)^2 + (y-cy)^2) sobre pixeles foreground\n",
    "    coords = np.column_stack(np.nonzero(bin_img))\n",
    "    if coords.size == 0:\n",
    "        inertia = 0.0\n",
    "    else:\n",
    "        dy = coords[:,0] - cy\n",
    "        dx = coords[:,1] - cx\n",
    "        inertia = float(np.sum(dx*dx + dy*dy)) / (coords.shape[0] + 1e-7)\n",
    "    return np.array([minr, minc, maxr, maxc, cy, cx, inertia], dtype=np.float32)\n",
    "\n",
    "\n",
    "def projections(img):\n",
    "    \"\"\"24 features: horizontal hist (10), vertical hist (10), diagonals (4)\"\"\"\n",
    "    if img is None:\n",
    "        return np.zeros(24, dtype=np.float32)\n",
    "    if img.ndim == 1:\n",
    "        side = int(np.sqrt(img.size))\n",
    "        img = img.reshape(side, side)\n",
    "    bin_img = (img > 0).astype(np.float32)\n",
    "    n = bin_img.shape[0]\n",
    "    # horizontal and vertical projections (sums)\n",
    "    proj_h = bin_img.sum(axis=1)\n",
    "    proj_v = bin_img.sum(axis=0)\n",
    "    # histogram into 10 bins each (bins computed over possible range 0..n)\n",
    "    h_hist, _ = np.histogram(proj_h, bins=10, range=(0, n))\n",
    "    v_hist, _ = np.histogram(proj_v, bins=10, range=(0, n))\n",
    "    h_hist = h_hist.astype(np.float32) / (h_hist.sum() + 1e-7)\n",
    "    v_hist = v_hist.astype(np.float32) / (v_hist.sum() + 1e-7)\n",
    "    # diagonals: sum over all diagonals then group into 4 groups\n",
    "    diag_sums = []\n",
    "    for k in range(-n+1, n):\n",
    "        diag_sums.append(np.sum(np.diag(bin_img, k=k)))\n",
    "    diag_sums = np.array(diag_sums, dtype=np.float32)\n",
    "    # group into 4 contiguous bins\n",
    "    m = len(diag_sums)\n",
    "    group_size = m // 4\n",
    "    diag_feats = []\n",
    "    for i in range(4):\n",
    "        start = i*group_size\n",
    "        end = (i+1)*group_size if i < 3 else m\n",
    "        s = diag_sums[start:end].sum()\n",
    "        diag_feats.append(s)\n",
    "    diag_feats = np.array(diag_feats, dtype=np.float32)\n",
    "    if diag_feats.sum() > 0:\n",
    "        diag_feats = diag_feats / (diag_feats.sum() + 1e-7)\n",
    "    return np.concatenate([h_hist, v_hist, diag_feats]).astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "def density_quadrants(img):\n",
    "    \"\"\"Devuelve 2 features: densidad izquierda, densidad derecha (suma de dos cuadrantes cada una).\"\"\"\n",
    "    if img is None:\n",
    "        return np.zeros(2, dtype=np.float32)\n",
    "    if img.ndim == 1:\n",
    "        side = int(np.sqrt(img.size))\n",
    "        img = img.reshape(side, side)\n",
    "    bin_img = (img > 0).astype(np.float32)\n",
    "    h, w = bin_img.shape\n",
    "    mid_h = h // 2\n",
    "    mid_w = w // 2\n",
    "    tl = bin_img[:mid_h, :mid_w].sum()\n",
    "    tr = bin_img[:mid_h, mid_w:].sum()\n",
    "    bl = bin_img[mid_h:, :mid_w].sum()\n",
    "    br = bin_img[mid_h:, mid_w:].sum()\n",
    "    left = (tl + bl) / (bin_img.sum() + 1e-7)\n",
    "    right = (tr + br) / (bin_img.sum() + 1e-7)\n",
    "    return np.array([left, right], dtype=np.float32)\n",
    "\n",
    "\n",
    "def extract_features_img(img):\n",
    "    fz = zoning(img)\n",
    "    fh = hog(img)\n",
    "    fhu = hu(img)\n",
    "    fl = lbp(img)\n",
    "    fs = skeleton(img)\n",
    "    fc = countours(img)\n",
    "    fr = pixel_run_length(img)\n",
    "    fconn = connectivity(img)\n",
    "    fgeo = geometry(img)\n",
    "    fproj = projections(img)\n",
    "    fdens = density_quadrants(img)\n",
    "    feats = np.concatenate([fz, fh, fhu, fl, fs, fc, fr, fconn, fgeo, fproj, fdens])\n",
    "    return feats.astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "# Use joblib Parallel (loky) which is more notebook/Windows friendly than concurrent.futures\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import tempfile\n",
    "import math\n",
    "import os\n",
    "\n",
    "\n",
    "def _extract_from_memmap(i, memmap_path):\n",
    "    arr = np.load(memmap_path, mmap_mode='r')\n",
    "    img = arr[i]\n",
    "    return extract_features_img(img)\n",
    "\n",
    "\n",
    "def _extract_batch_from_memmap(batch_inds, memmap_path):\n",
    "    arr = np.load(memmap_path, mmap_mode='r')\n",
    "    out = []\n",
    "    for i in batch_inds:\n",
    "        img = arr[i]\n",
    "        out.append(extract_features_img(img))\n",
    "    return out\n",
    "\n",
    "\n",
    "def _make_batches(n, batch_size):\n",
    "    for start in range(0, n, batch_size):\n",
    "        end = min(n, start + batch_size)\n",
    "        yield list(range(start, end))\n",
    "\n",
    "\n",
    "def extract_features(X, n_jobs=None, batch_size=None, use_mmap=True):\n",
    "    \"\"\"Extract features for X using joblib + memmap + batching to scale better.\n",
    "\n",
    "    - `use_mmap=True` writes `X` to a temporary .npy and workers read via mmap (no large pickles).\n",
    "    - `batch_size` (int) controls how many images each task processes; default chosen automatically.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    if n_jobs is None or n_jobs == -1:\n",
    "        n_jobs = max(1, multiprocessing.cpu_count() - 1)\n",
    "    if n == 0:\n",
    "        return np.zeros((0, 0), dtype=np.float32)\n",
    "\n",
    "    if batch_size is None:\n",
    "        # heuristics: aim for ~4-8 tasks per worker\n",
    "        batch_size = max(1, math.ceil(n / (n_jobs * 6)))\n",
    "\n",
    "    if n_jobs == 1:\n",
    "        return np.array([extract_features_img(X[i]) for i in range(n)], dtype=np.float32)\n",
    "\n",
    "    if use_mmap:\n",
    "        # save X to tmp .npy and let workers read via mmap\n",
    "        tmpdir = tempfile.gettempdir()\n",
    "        fname = os.path.join(tmpdir, f\"_emnist_mmap_{os.getpid()}_{np.random.randint(2**20)}.npy\")\n",
    "        np.save(fname, X)\n",
    "        try:\n",
    "            # create batches of indices\n",
    "            batches = list(_make_batches(n, batch_size))\n",
    "            results = Parallel(n_jobs=n_jobs, backend='loky')(\n",
    "                delayed(_extract_batch_from_memmap)(batch, fname) for batch in batches\n",
    "            )\n",
    "            # results is list of lists (in batch order) => flatten preserving order\n",
    "            flat = [f for batch_out in results for f in batch_out]\n",
    "            return np.array(flat, dtype=np.float32)\n",
    "        finally:\n",
    "            try:\n",
    "                os.remove(fname)\n",
    "            except Exception:\n",
    "                pass\n",
    "    else:\n",
    "        # fall back to passing indices but without memmap (still avoids copying entire X at once)\n",
    "        batches = list(_make_batches(n, batch_size))\n",
    "        results = Parallel(n_jobs=n_jobs, backend='loky')(\n",
    "            delayed(lambda batch: [extract_features_img(X[i]) for i in batch])(batch) for batch in batches\n",
    "        )\n",
    "        flat = [f for batch_out in results for f in batch_out]\n",
    "        return np.array(flat, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c0b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: orden y valores coinciden entre secuencial y paralelo\n"
     ]
    }
   ],
   "source": [
    "# pequeño test de verificación de orden\n",
    "X_small = X_train[:1000]\n",
    "seq = extract_features(X_small, n_jobs=1)\n",
    "par = extract_features(X_small, n_jobs=8)\n",
    "assert np.allclose(seq, par), \"Paralelo y secuencial difieren — revisar pickling/estado\"\n",
    "print(\"OK: orden y valores coinciden entre secuencial y paralelo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc17b460",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_features = \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m test_features = extract_features(X_test)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExtracted train features shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_features.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 332\u001b[39m, in \u001b[36mextract_features\u001b[39m\u001b[34m(X, n_jobs, batch_size, use_mmap)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;66;03m# create batches of indices\u001b[39;00m\n\u001b[32m    331\u001b[39m     batches = \u001b[38;5;28mlist\u001b[39m(_make_batches(n, batch_size))\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m     results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mloky\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_extract_batch_from_memmap\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatches\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m     \u001b[38;5;66;03m# results is list of lists (in batch order) => flatten preserving order\u001b[39;00m\n\u001b[32m    336\u001b[39m     flat = [f \u001b[38;5;28;01mfor\u001b[39;00m batch_out \u001b[38;5;129;01min\u001b[39;00m results \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m batch_out]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_features = extract_features(X_train)\n",
    "test_features = extract_features(X_test)\n",
    "\n",
    "print(f\"Extracted train features shape: {train_features.shape}\")\n",
    "print(f\"Extracted test features shape: {test_features.shape}\")\n",
    "\n",
    "np.savez_compressed(\"output/emnist_train_features.npz\",\n",
    "                    X_train=train_features,\n",
    "                    y=y_train)\n",
    "np.savez_compressed(\"output/emnist_test_features.npz\",\n",
    "                    X_test=test_features,\n",
    "                    y_test=y_test)\n",
    "\n",
    "print(\"Saved extracted features to: output/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
